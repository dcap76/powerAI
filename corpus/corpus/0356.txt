基于神经网络的股价预测

摘要

随着中国经济的快速增长和金融市场的不断扩大，股票这类对虚拟经济的投资越来越受人们的青睐。股市出现后，人们试图研究股价波动，掌握价格波动规律，学术界发明了各种研究方法来预测股票。 BP神经网络在大数据预测的经典算法中受到投资者和研究者的青睐。然而，BP算法由于其收敛缓慢而易于落入局部最小值，效率较低。

基于对股价预测问题的深入分析和各种预测股价方法的比较，本文通过建立遗传BP神经网络模型探讨了股价预测方法。首先将利用遗传算法搜索的最优个体作为BP神经网络的初始权重和阈值。然后，通过试错法确立隐层节点的数量，构建BP神经网络的模型。然后，使用BP算法训练网络，训练过程自动调整学习率。基于遗传算法的BP神经网络不仅可以发挥遗传算法的全局搜索，而且能快速有效地发挥BP神经网络的作用。两者的结合，加快了运算效率，提高了BP神经网络学习能力和预测股票的能力。

基于该算法的思想，本文构建了预测模型，以Matlab9.0为实验平台，进行模拟实验，选取上海和深圳300指数为实验对象，用前10天的收盘价和开盘价加上当天的开盘价来预测当天的收盘价。其中，将140天的历史数据中的前100组数据用作训练样本，最后30组数据用作测试样本。从收敛速度、稳定性和准确性的三个角度比较和分析BP神经网络预测模型和遗传BP神经网络的预测模型。实验表明，提出的基于遗传神经网络的预测股价方法具有一定的实用性。

关键词：机器学习；股价预测；BP神经网络；遗传算法;


绪论

1.1研究背景和意义

股票市场在全球金融体系中起着至关重要的作用，因为它允许公司通过交易公司所有权股份来筹集资金。但是，它不仅对企业本身很重要，而且还被用作银行和私人投资者的投资平台。为了获得良好的股票投资回报，对未来价格的准确预测至关重要。然而，预测股市是一个艰巨的任务，因为股票的价格走势受经济因素、业务因素、政治因素、市场因素和心理等因素的影响。从股市表面上看，股市在缺乏一定法律约束的情况下出现变化。同时，中国股民的结构具有特殊性，买家的心理状态和股票交易行为对股票走势有直接的影响，导致股份价格波动，不容易掌握股价。股市的变化和整个市场经济的发展有着密切的关系，在国民经济中发挥了非常大的作用。它的作用不只是受到广大投资者的关注，政府也十分关注。对于股票投资者，未来股价变动趋势预测越准确，收购的盈利几率和避免风险就越容易；国家经济发展在建设方面，股票预测研究也起着重要的作用，所以研究股价走势预测具有重大意义。

股票预测是基于过去和现在的股票价值来引入未来价值，这决定了股票预测研究对象不是一个特定的事件，而是一个随机的，不确定的事件，这需要使用匹配的科学预测方法来做出合理的推论。对于股票预测，基本特点如下：

（1）股票预测是一种非线性动态系统，股票市场是一个非常复杂的系统，没有准确的方式来满足任何一种股票预测，而且近年来发现试图找到一个非常精确的方法是不现实的，我们可以做的是在合理的范围内预测出错控制。

（2）根据股票市场各种因素的复杂关系，一般的预测方法难以准确预测。和股票时间序列相关的历史数据也很多，建立股票预测模型的一般线性方法显然是一个很大的错误，难以实现实际效果。

（3）由于股票系统的非线性动力学，必须使用股票预测方法来拟合非线性数据方法。目前，线性系统等多项成熟的方法，如多元线性回归分析，非线性系统处理理论不完善，进一步进行理论与实践研究。

（4）股价数据有一些波动的奇点。这些奇点可能对股票预测的研究有一定的影响。线性方法可以直接消除这些奇异点，但非线性系统认为系统的鲁棒性不能直接从我们的数据推导出这些奇异点。

（5）买家为投资者。投资者是非常主观的动态个人，有良好模式的股价历史数据，使得预测误差控制在一个很小的范围内，但由于股票受到个人对未来事件的影响，我们对股价走势的预测仍然有一定的不准确性。

（6）考虑到我们的股票市场受到明显的国家政策的影响，有必要通过科学的方法来预测国家政策的这个因素。


1.2国内外研究现状

过去很长一段时间，由于股市规模小，信息共享的速度太慢，股票的技术限制被分析，人们只能通过自己的主观判断做出决策和投资。随着近几十年股票市场的快速发展，信息披露的规范化和信息共享的多样化，人们开始寻求一些有效的预测方法来分析和研究股票市场，进行更有效的投资。但股市是一个复杂的系统，不仅受市场外部因素的影响，还受到自身内部对股市的影响，预测确实有一定的难度。但人们并没有停止对股票预测的研究和探索。

1.2.1国内外研究现状

1987年，神经网络算法第一次被应用于预测领域。此后，神经网络在预测研究中得到迅速发展。美国前沿金融公司使用神经网络来预测20世纪90年代中期的股票市场。在20世纪90年代，White利用神经网络来预测IBM股票的每日收益率。 [21]然而，预测结果不能令人满意，此外通过分析神经网络被捕获在局部最小值，发现该网络不能收敛到最小点。 1990年，Kimoto，Yada等学者利用神经网络技术开发TPOix预测系统[3]，该系统主要在东京证券交易所股票加权平均指数（类似于道琼斯指数）预测结果显示神经网络模型的预测结果优于TOPix加权平均值的结果。 1996年，Gen Cay在1967年建立了前身人工神经网络模型[41]，以道琼斯工业平均指数的移动平均线作为输入变量。1988年道琼斯指数分批进行了分析。预测结果表明，BP网络模型的预测能力明显优于简单移动平均法。 2000年，罗德里格斯等研究人员建立了移动平均规则和前向人工神经网络的综合模型。对西班牙股市的实证分析显示，基于预测结果进行的股票交易收益远高于收购后获得的收益。 2003年，G.Peter zhang实验结果表明，神经网络模型不仅具有比ARIMA模型更好的预测精度，而且具有处理非线性数据的优点。实验结果表明，神经网络模型不仅具有比ARIMA模型更好的预测精度。

另外，进入二十一世纪以后，神经网络在股市分析中已经出现了很多研究成果。 A. murat oi Bayogly和Ismet Bahadir比较了神经网络和贝叶斯估计的两种方法在股票市场交易中的预测效果[71。本文选择215个股票的历史数据，根据不同的标准对这些历史数据进行分析，得出结论：两种方法均可应用于股票市场，但神经网络方法的效果明显好转。Chi-Jie Lu认为，股票市场的数据非常嘈杂，时间变化非常强劲。他尝试使用完整的独立分量分析进行去噪，然后提出基于神经网络的股票趋势预测模型。该模型首先构建一个独立的，然后使用它来分析预测变量以产生独立的分量，然后去除数据以重建预测变量。重建的预测变量将包含低噪声信息作为神经网络模型的新输入变量。该模型使用日本日经225指数的开盘价来评估最终表现，结果表明，Chi-Jie Lu提出的新模式优于与神经网络模型相结合的小波去噪技术，但对神经网络的内部结构没有深入的分析和研究。 Hammd，M. Alhaj ali和L.hall使用BP多层神经网络分析了中东约旦股市的股价[9]，通过实证分析发现，与统计分析方法相比，BP神经网络预测方法获得更高准确性，预测能力更好，但是他们的研究并不涉及BP神经网络，一个一个地将问题逐渐转化为局部最小点。 Arnold F.Shapiro将三种方法与粗糙集、神经网络和遗传算法结合起来，独立处理时间序列数据，构建了一个综合预测模型[10]，进行数据处理和预测，既保留了每种方法的优点，也弥补了彼此。然而在研究过程中，不分析每种方法单独的效果对综合模型的影响，综合模型的有效性并没有直观的体现出来。来自TOBB大学的Murat使用神经网络模型来分析和预测TKC证券的数据。 [11]输入向量的选择从不同类型的模型开始，包括趋势，动机，模式和波动性，并验证数据。结果表明，与其他预测模型相比，神经网络预测模型更好，可用于预测投资组合的价格并预测短期交易。然而，研究仍然有一些主观性，没有详细的解释选择模型输入向量的基础和原因。 MelikeBildirici等将ARCH / GARCH模型与人工神经网络模型[12]相结合，分析了近三十年来土耳其股市的股票市场数据。结论表明，ANN-APGARH模型显着提高了股票价格预测的准确性，但仍然缺乏模型处理大规模非线性数据的能力。

1.3本文所做的工作

本文的主要内容是研究遗传神经网络在股票价格预测中的应用，主要针对BP算法在股价预测中的障碍，例如：收敛缓慢、有很大概率落入局部极小点等问题，使用遗传神经网络算法建立股票预测模型并验证其可行性。本文主要内容如下：

1、使用遗传算法优化BP神经网络的初始权重和阈值

通过遗传算法优化BP神经网络的权重和阈值。首先编码初始权重和阈值。然后，设置遗传算法的参数，计算适应度函数，对编码个体进行操作和重新计算。适应度函数确定是否达到适当的准确度。

2、优化BP神经网络的结构

首先确定网络结构中隐藏层节点数的近似间隔和范围，然后使用试错法计算隐层节点的具体数量。在此过程中，逐渐增加隐层神经元的数量，选择均方误差（Mean Square Error，MSE）作为误差的度量。在相同的训练频率下，选择与最小平均误差对应的隐藏层数。

3、提高BP网络的学习率

在训练过程中调整学习率，使小时候小，大时间大。可以非常随机地选择所选范围的初始学习率，您可以在评估条件时参考额外的动量，如果新错误大于过去错误的若干倍数，学习率将会降低，否则学习速率将保持不变，如果新的错误少小于旧的错误情况，则会增加学习率。

4、建立股票预测模型

利用前十个交易日的开盘价预测第十一个交易日的收盘价，股票预测模型设置为3层，输入层有20个节点，隐层有12个节点，输出层为只有一个节点。

5、使用Matlab9.0进行模拟实验

使用沪深300指数130套历史数据对网络进行训练和测试，并预测未来30天的沪深300指数收盘价。分析结果可以得出结论，预测模型具有更好的收敛性和稳定性，预测结果的准确性更高。

论文结构1.4

本文分为四章，具体安排如下：

第一章主要分析了进行股票价格预测的背景和意义，以及国内外股票预测研究现状，最后总结了本文所做的工作。

第二章主要阐述BP神经网络和遗传算法的相关理论知识。首先分析影响股票走势的因素，并比较股价预测方法。然后介绍BP神经网络和遗传算法及其在股票预测中的应用。

第三章分析如何通过遗传算法优化BP神经网络，提出遗传神经网络学习效果的改进，构建基于遗传BP神经网络的股票预测模型。

在第四章中，利用MATLAB的外部接口将股票数据导入到MATLAB中，对基于BP神经网络和改进遗传神经网络算法的股票预测模型进行了模拟和验证，验证了遗传神经网络遗传预测模型的可靠性和准确性。

总结了我所做的工作，分析了提出的方法的缺点，改进了方向。

第二章相关理论依据

2.1神经网络预测方法

神经网络由许多并行、高度关联的数据处理单元组成，类似于神经元。神经网络模型是基于对人类大脑信息处理机制的初步了解的分布式并行数据处理结构。神经网络根据训练数据对内部节点之间的关系进行连续调整，达到学习数据变化规律的目的，这可以在下一个时期预测数据趋势来实现预测功能。神经网络具有分布式存储、并行处理、容错能力强、非线性度高、自组织性强、自学习能力强、适应能力强等特点，被广泛应用于经济数据分析和价格预测。神经网络预测方法包括径向基函数神经网络、反向传播神经网络（BP）和感知神经网络[211]。在预测神经网络股价走势的具体过程中，有必要全面解决三个问题。它们是输入量确定、回溯期选择、神经网络算法及其参数确定的问题。讨论分析这三个重要问题，具体如下：

（1）解决相关投入数量澄清问题

解决股价走势，需要处理大量数据，包括历史数据和实时数据等大量内容，涉及的参数包括价格、数量等多项内容。虽然这些内容和数据看起来比较简单，但在实际操作过程中，解决相关数据输入输出是个大问题，完成准确的预测工作是非常困难的。其实，由于股价走势在综合技术分析过程中，股票开盘价、收盘价、数量等综合信息是根据人们的历史经验，以相关技术手段计算结果，从中发现股市走势的规律是很难的，使用神经网络预测方法可以实现选定网络的输入变量，预测未来股价走势。

（2）解决确定问题参数的神经网络算法

本文采用BP算法，可以全面实现股价时间序列问题，充分体现时间变化对股价变动的直接影响。

（3）解决回溯窗口的选择

在股市发展变化中，日均股价、技术分析指标受股市变动趋势的影响。随着股市的变化，这个过程实际上就是一个时间序列的变化，解决回溯窗口的问题，就是我们面临的一个重要问题。


2.1.2股票预测困难

股价波动受到干扰因素的影响，在以下几个方面有困难：

1、心理预期心理的不确定性。股权投资的目的是为了盈利，通过出售行为实现利润，投资者的心理影响预计会非常大。投资者不是完全理性的，但对心理偏好的厌恶感，会有“过度自信”，“放牧效应”等等，所以投资者预期会有非常强烈的心理不确定性和不可预测性，会影响股票价格随着时间的推移，这种效应变得越来越难以衡量。

2、股价数据非线性。股价和影响股价的因素数据之间存在很高的非线性度。股票价格预测系统应具有强大的计算能力来处理大量的非线性数据。传统的预测方法主要是解决线性数据预测的方法，股票价格预测难以成为高度非线性的复杂系统。

3、股价数据高噪音。影响股票价格的因素有很多，一些因素几乎完全无关，所以股价数据在这个过程中会包含更多的噪音，数据的高噪声会影响股票的预测准确性和准确性价格预测系统如果不消除等级，那就是股价预测过程需要关注的一个难题。

总之，股价预测是一个复杂的系统，具有高度的非线性特征，受到很多因素和功能的影响。

2.2 BP神经网络

通过上述股票预测分析，我们可以看出影响股票价格的因素有很多，而且价格变动是一个动态过程，难以量化，研究人员难以建立基于股票的历史数据。大多数传统统计方法都是基于时间序列的线性特征，大量的研究表明，股票价格的运作是非线性的，所以传统的方法不能对股票价格波动进行有效的分析和预测。 BP神经网络的基本原理是模拟人脑的思维。行为金融理论认为股价轨迹是人们变化的结果。所以人们以许多方式思考的方式可以反映股票价格的变化。因此，使用具有非线性特征的BP神经网络可以在理论上模拟股票价格的运作。

2.2.1BP神经网络基础

针对BP神经网络的研究可以起源于19世纪末。在神经网络的整个历史中，其发展分为四个阶段。胚胎阶段的第一阶段，从1890年到著名的美国心理学家W. James率先研究人类大脑结构和功能，到1969年，Minsky和Papert发表了《感知器》（Perceptions）。第二阶段是低估阶段，从1969年到1982年，J. J. Hopfield出版了着名的文章《神经网络与物理系统》（Neural Network and Physics system）。第三阶段是复兴阶段，从J. J. Hopfield研究论文突破性进展开始，1986年结束。D.E.Rumlhart和J.L. McClelland率领研究团队发表了《并行分布式处理》（Parallel Distributed Processing）。第四阶段是高潮阶段，1987年第一届国际人造神经网络学术会议作为标志，人们对人工神经网络的研究与应用的热情急剧高涨，至今依然处于上升之中。

BP（反向传播）网络是由误差反向传播算法训练的多层前馈网络[241]，它是最广泛使用的神经网络模型之一。BP网络可以训练和存储大量的输入输出模式映射，不会体现出表现此映射的函数方程。其学习方法是使用最陡下降法，利用逆向传播从而持续调整算法的权重和阈值，直到算法误差平方和最小[25.26]。 BP神经网络拓扑包括输入层、隐含层和输出层，如图2.1所示。


输入层从外部接收输入样本X，然后执行权重调整。在此过程中，将比较理想的输出信号和实际的输出信号，用得到的误差来校正权值。

在图中,…是输入采样信号，,…是网络输出信号。 其中，输入层、隐含层和输出层的输入和输出定义如表2.1所示。

各层输入输出定义

操作 输入层 隐含层 输出层

输入 X=（,…） G=（,…） M=（,…）

输出 G=（,…） H=（,…） Y=（,…）


同时，定义输入层到隐含层的关联权值为，隐含层到输出层的关联权值为，隐含层的输出阈值为，输出层的各结点输出阈值为，为学习速率。网络适应函数S：

f(x)=

输入采样信号受到权值的作用生成结果减去阈值，能够得到隐含层的各个输入：

=-

通过隐含层的输入调用S函数，能够运算出隐含层的输出

对输出层的输入M调用函数S，得出输出层的各结点输出Y。

=f()

根据输出层的实际输出向量Y=（,…）和期望输出向量O=(,…)能够计算出输出层各结点的误差

=(-)(1-

利用关联权值、输出层的一般化误差和隐含层的输出，计算隐含层各节点的一般误差{}，

=(1-)

用误差和隐含层各节点的输出校正关联权值。

（N+1）=（N）+

用误差和隐含层各节点的输出修正阈值

（N+1）=（N）+

使用隐含层各节点的误差{}和输入层的输入向量X=（,…）来校正关联权值

（N+1）=（N）+

使用隐含层各节点的误差{}和输入层的输入向量X=（,…）校正关联权值的阈值

（N+1）=（N）+

反复进行以上步骤，直到误差值达到指定的范围或者训练达到指定次数时结束。


2.2.2BP学习算法

误差反向传播（BP）算法是典型的监督训练算法。学习过程由两个过程组成，即信号的正传播和误差的反向传播。通过向后分配输出误差，将误差分配给每个层的子模块，以获得每个子模块的误差信号，进而调整每个子模块的权值。这样输入和输出问题的一组样本就可以被看作是非线性优化问题。神经网络学习是为了能够学习一个可以获得输出的模型。实际上学习过程在外部样本中不断调整过程的权重，而在这个过程中是调整规则的权重。在学习和优化过程中，使用梯度下降算法得到模型实际和理想输出之间的均方误差（MSE），以此达到神经网络训练的目的。它是一种非循环多重神经网络学习算法，算法流程图如图2.2所示。



计

算隐含层节点误差

数值学习

求误差梯度

全部满足

开始

初始化

提供输入特征向量和期望输出特

征向量

求隐含层、输出层各结点

求期望输出特征向量实际输出值的偏差

满足要求

开

结束





















是



否


否





是








BP神经网络算法流程图


BP神经网络的初始化包括在每个关联权重范围（-1,1）内任意分配一个值，选择合适的误差函数e，确立计算精度和最大学习次数M，有必要确定问题：

1、样本数据：第一要有一定量的典型和良好精度的样本。 将收集到的数据随机分成训练样本、检验样本（10％以上）和测试样本（10％以上），确定输入和输出变量值和数据预处理，输入数据值的一般要求在0和1之间。

2、神经网络拓扑结构确定：优先考虑3层BP网络（隐含层），最基础的要求是在达到尽可能少的隐含层结点的精度要求的同时，隐含结点数必须少于N-1（N是训练样本数）。另外，训练样本的数量必须大于BP神经网络模型的关联权重，一般是2?10倍。

3、神经网络训练：BP神经网络训练是应用误差回归网络权重的不断调整原理，让该结构的输出值和现有的训练样本的输出值之间的平方和最小或者小于预期。由于研究数量有限，主要取决于经验知识和设计师的经验。

4、学习率：学习率代表网络学习过程的稳定性。学习率的选择值得重视，大可能会使系统变得不稳定，学习率不够多可能会使得训练周期过小，收敛速度缓慢，无法逼近目标误差[2171]。于是，通常取较小的学习率来保障系统的稳定。从误差下降曲线可以看出，学习率的选取较为恰当，则误差下降速度较快，假使存在大的振荡，则说明学习率过大。在实际应用中，我们通常取0?1之间的常数。

5、模型的初始关联权重：BP神经网络算法本身的结构和性质会导致误差函数具有不少局部最小点，BP神经网络算法在最终收敛中，局部/全局最小点由不同初始权重的网络确定。转换函数Sigmoid要求分配初始权重在-0.5至0.5之间。

6、网络模型的性能和泛化能力：确定网络模型的泛化能力是高还是低，不是关注测试样本本身的大小，是要比较测试样本误差是否与训练样本和测试样本类似。

7、确定合理的网络模型：如果要确定全局最小点，第一步要做的是利用不断更改网络的初始关联权重来获取对应的最小点，然后找到最小的网络误差在极点上获得网络关联权重的最优解，为此网络的结果。

2.2.3基于BP神经网络的股票预测模型

股市数据量非常大，可能导致股市波动很大因素，这些因素之间的关系也非常复杂。基于这些大型模糊和非线性股票市场数据，传统的计算方法难以建立在合适的数学模型上。 BP神经网络具有非线性模拟、自主学习等优点。金融市场数据分析的方法得到众多研究人员的喜爱，并且经过他们的不懈努力，很多研究成果被发明出来。本节运用BP神经网络算法来构建股票预测模型，实现第十一个交易日的收盘价预测。反映股价的技术指标包括股票开盘价格、当天收盘价格、当天最高价格，当日最低价格。如果所有这些指标都用作预测模型的输入向量，则预测模型将不能承受如此大量的计算。此外，神经分支越多即输入变量的数目越多，神经网络的训练时间会越长，而且经实验表明，这种正相关增加趋势是呈指数增长。本文将利用BP神经网络算法来建立股票预测模型，将网络输入定作10个连续交易日收盘价数据，从而预测第11个交易日收盘价。使用BP神经网络进行股票预测的具体过程如下：首先根据用户输入的股票价格指数确定输入样本，并将样本数据归一化，然后输入到BP神经网络。然后，BP神经网络用于独立输入数据学习，测试，根据网络权重的输出自动调整。最后，通过不断重复学习和调整，实现正确配套训练所需的产值，达到预测未来股票价格的目的。 BP神经网络预测模型的大致过程如图2.3所示。










开始

数据输入

数据归一化处理

网络建立及初始化

网络训练与学习

满足要求

网络仿真

结束


















否



是








BP神经网络预测模型的流程图



1、选择输入和输出样本集

利用MATLAB的外部接口将股票数据导入到MATLAB中，并从中提取130个样本数据，样本数据分为两类，当进行网络训练时，我们用前100个当做是训练输入样本，剩下的30个当做测试时所用数据。

2、样本数据进行归一化

为了保持数据的原始特性，输入数据被预处理并转换成[0,1]之间的数字。

3、确定BP网络预测模型结构

结果表明，三层前馈神经网络可以以近似任意精度逼近任意非线性关系。 在本文中，我们搭建了一个3层BP网络结构来对股价的走势进行预测。 输入层神经元数是n = 10，输出层神经元数是m = 1，BP神经网络隐层神经元数为12，规划的BP神经网络预测模型在图3.2中：




4、训练网络

网络的初始权重通常采取较小的任意常数。 在该文中，我们假定初始权值是在（-1,1）区间的某一任意权重。 隐含层激活函数选择双曲正切S型传递函数tansig，输出层激活函数选择线性传递函数purelin学习算法采用具有高收敛速度和高精度的Levenberg-Marquardt算法。 训练2000次; 使用误差平方和作为误差函数，目标误差为1.0e-30; 学习率设定为0.01。

5、网络仿真

股票预测模型的BP神经网络采取调用Sim函数的方式来模拟仿真数据，调用mse函数来计算拟合误差，最后评估计算出来的结果。

2.3遗传算法

2.3.1遗传算法基础

在上个世纪八十年代，密西根大学的荷兰教授和他的同学们在自然和人工自适应系统的研究中开创了遗传算法（GA）的思想。GA是一种直接搜索算法，遗传算法的思想来源于达尔文进化与遗传学理论，不依赖于问题本身，而是解决问题。基于科学家们对GA的多年研究，目前遗传算法已经广泛应用于社会科学、经济学和机器学习等方向。利用“291”概念的大量进化和遗传方面的遗传算法，结合达尔文进化论和遗传学理论提出了一种新的直接搜索优化方法。作为一个新的事物，遗传算法重新定义了一些概念，包括：

位串（Bit String）：在染色体（染色体）的遗传学中，是表示个体的概念。

群体（Population)）：对应于染色体收集的遗传学，是代表性的组合。

基因（Gene)：是构成字符串的一种元素，它可以表示每个个体独有的特征。

基因特征（Gene Feature）：基因位点相同的基因值。

基因位置（Gene Locus)：基因在染色体上的坐标。

适应度（Fitness)：将单一染色体适应环境，适应良好的个体将优先继承，相对较差，适应性差，获得遗传的可能性非常小。

其基本原理是处理染色体上的基因，然后找出理想的染色体来进行试验，这个原理也可以理解为模拟自然选择和遗传发生的复制，交叉和突变现象，原则可以来自任何一组初始种群，选择随机选择、交叉和突变，将导致一组对环境更加敏感的个体，并最终将群体演变成更好更好的搜索空间区域，通过这样的一组行动将继续发展，直到最适应个人环境，并最终得到最优解的问题[30]。

遗传算法在问题优化过程的运行中是完全随机的，通过求解最优运算直到遗传代数或适应度达到最终要求，才能获得最优解。算法的过程是一个循环的过程，基本过程如图2.3所示[3]



从图2.3可以看出，算法所需的基本步骤包括：

1，编码策略选择。要解决问题的解决方案，首先必须选择适当的编码策略，将所选代码解决的问题转化为字符串结构空间;

2，选择目标函数来定义适应度函数f（x）;

3，选择遗传策略。确定初始种群数，具体遗传操作，设定概率值等遗传参数;

4，人口初始化;

5，通过函数计算适应度值f（x）;

6，根据遗传策略，再次对群体进行遗传操作，实现人口的演变;

7，确定组的进化是否在多大程度上，是否满足先前设定好的循环条件，如果不满足，则返回步骤6，或直接通过修改遗传策略返回到步骤6。

2.3.2遗传算法求解过程

1，遗传密码

染色体的编码是遗传算法中需要解决的主要问题。好的和坏的编码直接影响整个遗传算法是否收敛，是否更快的收敛。通用编码方式一般为三：符号编码，二进制编码，浮点编码f3列。如果您使用上述三种编码方法之一，无论根据具体问题选择哪种类型的编码，只需充分了解遗传算法中三种编码方法的特征，从而做出正确的染色体代码将会有一个收敛可以和速度最好的解决方案。这里有一些三种编码方法做一些介绍。

（1）符号编码

符号编码在使用过程中不是常用的编码方法，因为在交叉和突变方面难以实现这种编码。字符串的符号组合是一些符号或字母，而这些符号和字母没有具体含义，而是一个代码。在问题难以以数字和二进制方式进行编码的情况下，或者在特定方向上解决实际问题的情况下，易于使用编码。例如，遗传算法中的块编码。

（2）二进制编码

二进制编码在使用过程中是非常常见的编码，其特点是操作简单，无论是编码还是解码都比较简单。二进制编码是0和l的组合，易于实现编码和解码，遗传算子的操作过程比较简单。然而，二进制编码的缺点也是很多的。对于连续多维函数的一些优化问题，它不是可测试性，不能直观地表达，并且编码精度受到编码长度的限制。在浮点编码和二进制编码时容易产生对方的错误，从而影响整体的成败。二进制编码具有优点和缺点。

（3）实数编码

实际编码也是使用编码方法最常见的，相对于二进制代码，实际编码更适合于连续函数优化问题。对于高精度的需要，需要对大量真实编码的值进行编码更为合适。与二进制码相比，编码空间的实数也更大。然而，使用浮点编码来注意，染色体的值必须在浮点范围内，否则解将会溢出。总的来说，实数编码有更多的优势。

2，人口初始化

遗传操作前必须有涉及进化的原始人群，人群可以随机生成，可以由用户给出。人口规模的选择很重要，如果选择人口太大，虽然可以找到最优解，但收敛速度相对较慢，这需要很多时间;如果你选择一个小的人口，虽然收敛速度更快，但是找到的解决方案并不一定是最佳的解决方案。因此，人口规模的选择应以实际问题为依据，以前的经验合理设定，考虑到收敛速度和遗传结果。

一般来说，初始组可以采取以下策略：根据问题的固有知识，尝试把握整个问题空间分布范围内的最优解占用空间，然后根据分布范围设置初始组;您也可以随机生成一定数量的个人，然后选出最初添加到初始组中的个人。重复该过程直到初始种群中的个体数目达到预定大小。

3，适应度函数设计

适应度函数是一个独立的个体，其范围定义的领域，功能是不断的不同的，无论这些问题是不是固定的限制，其设计是基于现实的解决方案，适应度函数设计会影响质量对于遗传算法的搜索结果，因为遗传算法的选择操作是基于个体的适应度值。组中的每个人是否被消除，该度量是根据适应度函数的个体的适应度值。在自然界中，每个生物体的演化是适应周围的自然环境，健身功能作为环境的性质，看每个人的个体，离开个人能够适应个人的环境，通过演化，将更适应个人，从而提高人口整体竞争水平。适应度函数通常由正在研究的问题的目标函数来转化。

这里有一些最常见的适应度函数：

（1）直接从要解决的目标函数中转化的适应度函数，即：

当目标函数是求解最小化问题时，Fit（f（x））= - f（x）

当目标函数是求解最大化问题时，Fit（f（x））= f（x）

要直接解决的目标功能的适应度功能太简单，有两个方面的弊病：一方面可能与非负面需求的概率相反;另一方面，各种适应度值的分布，所以平均适应度不能完全反映人口的平均表现，而且还没有看到遗传算法的整体优化。

（2）如果目标函数最小化，则：


如果目标函数是最大化的问题，则



其中，是f（x）的最小估计。 与第一种方法相比，第二种方法是一种改进的适应度函数，称为“极限施工方法”，但其阈值难以估计或不能估计。

（3）如果目标函数最小化，则：



1类似于2，C是目标函数边界的保守估计。在遗传算法的过程中，适应度函数的选择是关键的一步，这将影响遗传算法的演化，这可能会影响遗传算法，从而找到更好的结果。

4，遗传操作

遗传算法由三个基本的遗传操作组成：选择操作，交叉操作和变体。这三种遗传算法是遗传算法的核心，它们可以产生新的群体，然后完成整个群体的演化。

（1）选择运算符

在遗传算法中，选择找到更适应个体，消除低适应性个体。操作的选择允许优秀的基因被保存，导致更高的健康个人[331]。选择操作是通过一组个人来适应能力的估计，以下介绍今天几个主要的选择运算符：

A）适应度比例法

健身比法也称赌博选择方法，是一种常用的方法。这样一来，个体在适应水平和个人能力水平可以从概率中选出的群体是一定的比例，其理论基础如下：

我们可以设一个群体为N，其中一个是i，其适应度是，所以个体i被选择的概率是：



通过上述公式，我们可以看出，如果适应度的适合度值较低，则选择个体的概率将较小。另一方面，适应性越高，个人被选择的概率就越大。

B）最好的个人保存方法

最好的个人保存方法是在人口中，具有较高适应度的个体不必参与任何遗传操作，直接拷贝，继承到下一代。这种方法避免了具有高适应度的个体的破坏，但不能单独使用。如果给定人口中没有最优解，则该方法不太适合本地解决方案，所有这些都需要其他选择算法的组合可以更全面。

C）期望方法

在选择投注时，当个人数量小时，不能完全反映个人的适应度。可能存在高度的适应度被淘汰，并且保持较低的适应度，该方法的预期值可以解决这个问题，主要思路如下：

计算组中每个个体的期望值：


②如果个人被选中并交叉配对，下一代计算，期望需要输0.5;另一方面，如果个人没有参与交叉配对操作，那么预期的数量应该减少1。

③期望小于零的个人不再参与任何选择。

D）排序选择方法

该方法基于适应度计算的功能，首先需要计算每个人的适合度值，然后根据约定的概率对某一种方式排序的概率进行排序，从而使每个人概率是他们自己的选择概率值。

E）联赛选择方法

该方法是将最高适应度的组直接输入到下一代继承中，每次执行迭代直到迭代结束。

（2）交叉算子

跨越的思想是保留遗传算法中良好个体的特征，探索新的遗传空间，产生新的个体，并保持多样性[341]。交叉运行可以提高人口的整体适应度，主要交叉方式如下：

A）一点交叉

单点交叉是一个相对简单的交叉，在个人的基因串中设置一个交叉点，交叉点的设置是随机的，交叉的，两个人之间交叉的前后两个部分交叉。如果基因组具有N个编码位置，则可以跨越N-1个点。

B）算术交叉

当浮点编码时，算术交叉的选择是一种比较常见的形式。新的代码串由两个子代码的任意组合生成。例如，假设两个子编码字符串，：进行算术交叉操作，并且通过该交叉操作生成的两个新的编码字符串如下：


在上述公式中，编码的字符串X1和X2是组中的母体染色体，、是算术交叉后获得的后代的个体，a∈（0,1）被设置为常数，上述操作过程中，使用交叉运算是均匀算术交叉的方式。当使用算术交叉操作时，需要设置线性运算的组合系数，然后根据上述公式可以得到两个新的编码字符串，代码前后的交点需要特别注意，一定要做同样的格式，长度相同，是促进遗传操作实施的唯一途径。

（3）变异算子

为了保持人口的多样性，有必要改变单个基因序列的某个位置的编码，这是突变算子的基本内容。当使用二进制编码时，通过选择一些基因的值进行否定，即1→0或0→1进行突变。

一般来说，变异算子的实现基于：

（A）确定该基因座是在群体中所有个体的编码范围内随机选择的;

（B）基因突变的概率以提前设定的突变概率P进行;

遗传算法中使用变异算子有两个目的：（1）当遗传算法搜索最优解时，出现悬停现象，变异算子具有随机搜索的能力。它提供遗传算法向最优解逼近。如果突变概率太大，个体接近最优解，整个搜索过程被破坏。（2）遗传算法需要保持人口的多样性，遗传算法需要保持人口的多样性，避免“早熟”现象。

存在交叉算子，遗传算法具有强大的全局搜索能力，是遗传算法中最重要的遗传算子，遗传算法的变异算子提供了本地搜索能力，因此需要将其作为运算符的辅助函数。在遗传操作过程中，只有当交叉算子和变异算子结合使用时，全遗传将快速，准确地解决问题。在解决复杂和现实的问题时，基本的变异算子不能满足，这导致了对变异算子的更多研究。以下是几种变体方法：

基本位变化

基本位变化主要用于二进制编码，即随机选择一些基因位，然后根据所选位上的突变概率为负，将1变为0或0变为1。

B）均匀变化

当编码方式为浮点编码时，使用均匀的变化更多。通过以较小的替代基因座上的原始基因的概率来代替均匀分布的随机数来进行均匀变化。

C）边界变化

根据上述操作的均匀变化进行边界变化。在执行此操作时，我们需要选择位于轨迹上方的两个相应边界基因的值，并选择其中一个被替换。当没有其他约束时，遗传编码很长，这种变化会产生负面影响。只有当个人接近最优解时，这段代码才会起到很好的效果。

D）不均匀变化

变分运算符与人口的进化代数相关联，因此在进化的早期阶段，变异范围具有相对较大的空间，而在进化过程中，变异空间将越来越小，操作员接近零。所有的变异算子对整个遗传进化都有微调效应。

5，参数选择

根据遗传算法的应用，我们需要设置一些参数，包括总组的大小，染色体的长度和各种操作符的出现概率。这些参数是重要的，需要设置为适当的参数值，因为它们与以后优化的结构有关。下面我们将对这些参数进行一些简短的描述。

（1）染色体长度选择

染色体的长度不尽可能长，染色体计算精度的长度虽然较高，但计算时间却很长。为了平衡计算精度和计算时间，有学者在优化过程中研究了染色体编码，同时具有良好的遗传优化效果。

（2）人口规模的选择

人口规模的大小应该在适当的范围内，如果所选择的人口规模太大，可以找到最优解，但如果所选择的群体规模太小，遗传时间将会使遗传时间特别长会很短，但不一定找到最优解。因此，人口规模的选择应根据实际问题，一般选择范围：20?200。

（3）交叉概率的选择

由于交叉算子的存在，遗传算法将具有全局搜索的能力。交叉概率的选择也应在适当的范围内，交叉概率太大会导致优秀基因的损失，交叉概率太小会影响整个遗传的效率。在大多数情况下，交叉概率的选择范围从0.6到1.如果在遗传过程中，使用自适应调整交叉概率，可能会有更好的结果。

（4）突变概率的选择

突变操作是遗传位突变操作的个体编码，变异概率必须选择合适的范围，一般变异概率在0.005?0.01之间。过多的突变概率将导致个体接近最优解的更大变化，这不利于收敛;变异概率太小将导致“早熟”现象。如果遗传过程中使用自适应调整突变概率，可能会有较好的效果。其实在遗传算法的实际应用中，没有一套数据可以应用于所有参数的情况。参数的选择受到很多因素的影响，没有绝对的标准，如果要选择最佳参数，则需要根据实际问题进行深入研究。

2.3.3遗传算法的优点

遗传算法在处理复杂系统优化方面具有很强的适用性。遗传算法在搜索过程中，只需要确定目标函数的搜索方向和相应的适应度函数，遗传算法为解决复杂系统问题提供了一个共同的系统，它不依赖于具体领域的问题可以广泛用于许多科学[35'61。与其他系统优化搜索算法相比，遗传算法在解决系统优化方面具有很大的优势，主要表现在以下几个方面：

遗传算法由于其进化特征，解决问题的方法并不多，经过编码处理。遗传算法应用于遗传过程中基因的遗传和遗传过程，导致优化过程的适应性。编码问题的方法比一般算法更为普遍。优越。

2，遗传算法从多个搜索点同时进行搜索，有利于全局优化。遗传算法从解决方案的求解器开始，而不是从单个解决方案开始。传统优化算法的主要缺点是单点搜索开始，算法很容易陷入局部最小点[37]，这不能解决全局最小点，直接进入局部最优解。遗传算法可以同时处理群体中的多个个体，具有潜在并行性。因此，遗传算法整合了定向搜索和随机搜索的优势，在更好的区域搜索和强大的空间扩展之间取得了一定的平衡。

3，遗传算法只需要根据适应度函数值即可确定搜索方向f3 81.其最大的优点基本上不用搜索空间知识或找到其他辅助信息，只有适应度函数值可以评估个人，作为相应遗传操作的基础。一些传统的优化算法使用辅助功能信息来根据目标函数值来确定搜索的方向。适应度函数不受连续可微约束的约束，其定义域也可以根据需要任意设定。该特征使得遗传算法的应用大大扩展。这种确定搜索方向的方法使得在具有高适应度函数值的解空间中定位搜索空间变得容易，从而在一定程度上提高了搜索的效率。

2.4总结

本章介绍了BP神经网络的原理和算法，并分析了BP神经网络在股票预测中的应用。同时介绍遗传算法的原理和基本操作，分析遗传算法在优化问题求解中的优势。








第三章基于遗传神经网络的股票预测模型

评估学习算法有许多标准，但核心依然是：简单性，可塑性和有效性。一般来说，简单的算法很难有效;塑料算法不是太简单;有效的算法需要完善和特异性，从而与可塑性和简单性相冲突。

BP算法是基于梯度法，简单和塑性是其主要优点，但BP算法这种方法也有其缺陷，一方面收敛速度较慢，另一方面也受到局部极小的麻烦;遗传算法是一种全球搜索算法，它是从多个初始点到多方向搜索组的潜在解决方案，该搜索允许其跳出局部最优解的能力，具有良好的全局搜索能力。为了补偿BP算法的缺点，提高算法的效率，我们可以使用遗传算法优化BP神经网络。目前，有三种常用的优化方法[41]：

（1）使用遗传算法优化BP神经网络的权重和阈值;

（2）采用遗传算法优化BP神经网络的拓扑结构;

（3）利用遗传算法对BP神经网络学习规则进行优化，使其能够适应问题和环境的要求。

3.1遗传神经网络算法

遗传算法优化BP网络包括三种方法，包括：

1）连接权重和阈值的优化[42]

在学习BP网络的过程中，根据连接权的一定变更规则获得连接权重，在训练过程中进行连续调整，以获得较好的连接权限分配。然而，由于要优化的目标函数非常复杂，BP算法不能使用一维搜索方法来计算每个调整的步长，导致算法的效率。如果训练时间太长，则BP算法将落入局部最小值，无法获得最优连接权重分布。使用遗传算法优化连接权可以解决这个问题。具体优化过程如下：

（A）

首先，随机生成一组分布，形成一系列权重（或净值），使用编码方案进行编码，然后构造一个表示网络权重分配的字符串，因为以前的网络结构并且学习规则已经确定，则字符串对应于权重和阈值以获取神经网络的特定值;

（B）

其次，计算新生成的神经网络的误差函数，通过该函数确定其适应度函数的值，一般来说误差越大，适应度越小;

（C）

将个体中适应度最大的直接送到下一代;

（D）

最后，目前一代群体进行交叉和突变等遗传操作，造成新一代群体;

（E）

重复步骤b-d，不断发展初始权重分布直到满足训练目标。

2）网络结构优化

网络结构由网络拓扑结构和节点转换功能两部分组成。优点结构将严重影响网络处理能力，良好的结构需要同时满意解决，不产生冗余节点和冗余连接。到目前为止，人们在设计网络结构时，一般使用以下两种方式，首先是预先确定的，二是使用增量或减少检测方法。增量检测方法是：在训练过程中，从较小的网络结构（最小数量的隐层，节点和连接权），根据具体需要不同的问题，逐步增加各种结构部分，直到找到相应的网络结构解决问题;使用该方法的减少检测方法恰恰相反。通过遗传算法演化神经网络结构的步骤是：

（A）随机生成N个结构，对每个结构进行编码，使得每个编码的个体对应于一个结构;

（B）以多种不同的初始权重分布训练个体浓度的结构;

（C）根据培训结果或其他策略确定每个人的适应度;

（D）选择一些具有最大适应度值的个体，直接继承下一代;

（E）遗传作业，如当代一代的交叉和突变以产生下一代群体;

（F）重复b-e的步骤，直到当前一代的个人能够满足要求。

3）优化学习规则

在神经网络系统中，学习规则决定了系统的功能。在采用遗传算法之前，先进行神经网络训练中的学习规则。采用遗传算法后，神经网络中的学习规则将演变为满足问题和环境的要求。进化学习规则的过程可以描述为[44]：

（A）随机生成N个个体，每个个体代表学习规则：

（B）构建训练集，每个元素代表一个结构，连接是一个随机或预先确定的神经网络，然后用每个学习规则对训练集的元素进行训练;

（C）计算每个学习规则的适应度;

（D）根据适应度选择;

（E）遗传操纵每个编码学习规则以产生下一代个体;

（F）重复b-e步骤，直到满足要求。

遗传神经网络的构建步骤主要包括优化方案，编码方案，适应度函数，遗传操作和神经网络的训练算法。

1）确定优化程序

您可以选择使用4.1.1中描述的优化方案之一，或组合多个场景进行优化。在本文中，方案1）用于使用遗传神经网络优化BP神经网络的权重和阈值。

2）确定编码方案

权重本身是真实的，如果它们是二进制数编码实际上是一个离散值来逼近权重，这可能是由于一些实际重量不能在网络训练中有效表达失败。二进制代码当字符串的长度也需要时，太长时间会导致遗传算法训练解空间太大，算法需要很长时间才能得到最优解，太短将导致精度不够。实际编码方案非常直观，不会有精度不够的情况，但也有明显的缺点，可能是一些不必要的遗传算子设计问题。

3）确定适应度函数

在遗传算法中，适应度的概念用于测量优化计算中每个人的优势，可能达到或接近或有助于最优解。在神经网络优化研究中，经常使用输出误差平方互惠作为染色体的评估函数。然而，人工神经网络的性能评估功能的选择是遗传算法的关键。考虑到网络训练误差，我们应该考虑网络结构和泛化能力的复杂性，从而可以利用评估函数优化参数方向，并逐渐接近参数的最佳组合。

4）确定遗传操作

遗传操作的目的是使用选择，交叉和突变等遗传算子，使由个体神经网络组成的群体从上一代演变为下一代。遗传神经网络中的遗传操作与简单遗传算法中的遗传操作相似，有时还需要设计专门的算子。

5）确定训练算法

首先，通过遗传算法优化BP神经网络的权重和阈值，并在解空间中找到更好的搜索空间。然后，BP算法用于搜索该小解决方案空间中的最优解。

3.2改进的遗传神经网络算法

3.2.1设计遗传算法的一部分

1，编码

为了提高股票预测模型的精度和效率，本文采用实数编码方法，设计了种群数量M，每个群体均包含L个基因（连接权重）：

其中R，S1和S2分别表示输入层，隐藏层和输出层中的节点数。编码过程中，前一个R * S1编码为W1，后面是W2的S1 * S2码，后面是B1的s1编码，B2的最后S2码。

2，人口初始化和运行参数的设计

首先确定一系列值，在范围内然后随机产生初始群体，是通过实际编码染色体的初始权重和阈值组成获得的。在本文中，根据标签间隔法，参数范围可以分为几个小间隔，间隔数等于群体数，每个分离的单元产生初始群体。因此，初步人口可以均匀地分布在解决方案的范围内，人口不会太大，不能聚集或高度分散，从而保持人口多样性居住的可能性增加。在遗传算法中选择的一般操作参数包括种群大小M，个别代码串长度L，交叉概率Pc，突变概率Pm，循环终止代数T等。

3，适应度函数的定义

适应度用于评估个体的优缺点。适应度越大，个体越好，适应度越小，个体越小。个人根据适应性的大小选择，以确保个体具有更好的适应性再现后代的机会，从而可以继承良好的特征。是一个非负数，是确定算法搜索方向的基础。因此，遗传算法要求适应度模型必须使用误差的平方和的倒数作为适应度函数，即输出值与神经网络的实际值之间的平方误差之和的倒数，这意味着误差越大，适应度越小，误差越小，适应度越大。



其中P是个体选择概率值，q是为最优个体选择的概率值，m是初始种群的大小，n是个体在群体中的位置。

第三步。

循环选择，计算概率值的选择，为了选择合适的交配个体，往往需要多轮。每轮选择过程在[0,1]之间产生均匀的随机数作为选择指针，用于确定所选择的个体。选择交配个体，然后随机分配交配对。

（2）交叉算法

在真正的染色体中，在群体中随机选择两条染色体x和Y。根据交叉率，交叉运算符随机转换群体中两个个体的一些基因以产生新的基因组合，将有益基因组合在一起。具体公式是：


在公式中，r是[0,1]之间的均匀随机数。

（3）变异算法

在基因交叉后产生的亚种个体可能具有小概率或步长的突变过程。方差算法主要采用非均匀变异算法，公式如下：


在上述方程中，t是当前进化代与最大进化代的比值。d（Xi）是染色体Xi，左右边界a和b，形状因子k，当前进化代和最大进化等价的函数。

3.2.2神经网络构建部分

1、改进的网络结构

（1）输入输出层数据

衡量股票市场变化的指标有很多，其中包括股票开盘价，当天收盘价，当天最低价，当日最低价，平均价格，回报率，数量，营业额，营业额，营业额，幅度，共有几十个[471。如果所有这些指标都用作预测模型的输入向量，则预测模型将不能承受如此大量的计算。更重要的是，神经网络的训练时间将随着输入变量的数量呈指数增长。因此，本文将重点关注开盘价，收盘价两个最重要的指标。

A）开盘价，也称开仓价，是指每股交易后每个交易日开盘后的证券交易所中的某些证券。

B）收盘价是在证券交易所一天交易活动结束前最后交易的交易价格。目前上海和深圳股市收盘价并不完全是交易价格的最后一笔交易，而加权平均价格也称为收盘价已调整。

陶的三个公理，即市场行为是包容性的，市场行为根据进化和历史的趋势将重演'481。根据历史将重复这个公理，本文选择了收盘价前11个交易日的前十大交易目标收盘价格预测。也就是说，BP神经网络的输入节点数为10，输出节点数为1。

（2）隐藏层节点的数量

BP网络具有强大的非线性映射能力，BP神经网络至少包含三层，即输入层，隐层和输出层。 3层BP神经网络可以实现任意非线性函数的逼近。为了提高数据的准确性，可以通过增加BP神经网络的层数和增加隐层中的节点数来实现。然而，增加隐藏层数将使网络复杂化，网络训练时间呈指数增长。因此，本文中的预测模型只包含一个隐式层。

确定隐层节点数是一个比较复杂的问题[491]。虽然增加隐层中的节点数量可以提高预测的准确性，但也增加了训练时间。如果训练时间足够长时间，神经网络可能会“记住”培训集的所有细节，而不是创建一个忽略细节的模型，而且我们称之为这个条件太多了。虽然这种“模式”在训练集中的精度非常高，而如果使用其他数据将会快速下降的准确性。目前，有必要确定神经网络中隐层节点的数量。过程如下：正向传播，数据从输入到输出的过程是前向和后向传播过程，后一个节点从连接的节点传递值，然后将该值加权输入适应度函数，获得新值，然后描述训练完成后神经网络的传播。训练中心由预测变量定律。现有公式不准确计算隐层中的节点数，但经验估计，我们在文本中作为初始值的试用方法参考。用于确定隐层节点数量的公式由以下三个公式组成


在上述公式中，m是指要获得的隐层节点的数量，n表示输入层节点的数量，a是1到10之间的常数。文章选择公式（3.9）来确定近似范围的隐藏层节点数，然后通过试验方法确定[9,14]范围内隐层节点的数量。增加隐藏层节点的数量，并使用均方误差（MSE）作为误差的度量。训练后，在相同训练次数的条件下，不同隐含层节点个数的均方误差如表3.1所示。


从表3.1可以看出，隐藏层节点的平均数为12，隐藏节点的平均数为12。

2，数据预处理

库存历史数据在各种技术指标之间的幅度差异较大，为了防止训练时间过长，误差过大等问题，数据必须归一化[5]。所谓的数据是归一化的，也就是数字映射到[0,1]或[-1,1]或更小的范围。 Matlab在内部函数premnmx中，Postmnmx，tramnmx可以将数据归一化为（-1,1），本文用于premnmx函数。现在，其语法如下：

[pn，minp，maxp，tn，mint，maxt]=premnmx(p，t)；

其中minp和maxp分别表示原始采样数据组件中的最小值和最大值，pn是网络输入数据。 Mint，maxt分别表示输出数据组件中的最小值和最大值，tn为目标值输出数据。

为了确保网络的输出数据和输入数据的数量级，其中网络训练输出后需要进行反归一化，使用数据回归归一化函数postmnmx实现，其语法是：

[P，t] = postmnmx（pn，minp，maxp，tn，mint，maxt）用于将矩阵pn，tn映射到归一化之前的范围。由于使用归一化数据进行网络训练，训练网络结构适合返回经过一系列数据后，再用训练网络进行测试和预测，相同的输入值应归一化，并反馈归一化过程的输出。

3，提高学习率

学习率自适应调整学习率也称为步长，在实际应用过程中，难以将最佳学习率从头到尾设置为常数，但在标准BP算法中设置为常数在错误的表面上，如果增加学习率会减少学习和训练的数量，从而提高效率。然而，如果学习率太大，则由于误差太大的表面中的学习速率，由于表面的波动导致的训练结果的不准确性，迭代次数将增加。所以为了提高学习率，不会产生冲击，更好的解决办法就是使小步调整小，时间大。您可以选择初始学习率的范围，也可以在添加动量时参考判断条件。如果新错误小于旧错误，学习率就会增加;如果新产生的误差超过了过去误差的一定倍数，则学习率降低;其余的情况保持学习率不变。上述方法可以确保网络总是最大限度地提高学习率，并进行训练，如果相对较大的学习率可以使神经网络模型进行训练和训练，为了使误差不断下降，增加在培训中学习率，以便能够以更高的学习速度学习。然而，如果学习率的选择太大，就不能保证误差不断下降，从而根据学习过程是否稳定调整来减少学习率。

对于股市价格预测，很难选择合适的学习率[53]。通常是凭借研究者的个人经验获得的。即使获得了自适应学习率，在研究的开始和结束时也不会采用相同的学习率。所以为了解决这个问题，可以在训练过程中，使模型自动调整学习率。如何解决这个问题直接关系到预测的效果。该模型采用自适应学习率调整公式：


其中E（k）是第k步误差的平方和。

4，BP神经网络训练

通过遗传算法获得的最佳染色体（最佳权重和阈值）进行解码，然后作为初始值复制到BP神经网络。基于此，使用准备好的数据训练BP神经网络，以获得训练有序的BP神经网络。大多数情况下，当网络的训练能力好的时候，预测能力也很强，在一定程度上，随着训练能力的提高，网络预测能力相应提高1541.但这一趋势也有一定的局限性，当这个限制时，用训练能力来提高预测能力的下降，也就是所谓的“过度配合”现象。因此，遗传神经网络计算不能盲目追求最小的训练误差，只要实时检测误差率变化，可以确定最佳训练次数。

3.2.3算法运算流程

在本文中，提出了一种自适应遗传算法，其采用实数编码方法和适应度函数来设置网络样本集预期输出误差平方和的倒数。轮盘法用于选择交叉运算的实数交叉法，使用非均匀变异算法进行变异运算。遗传神经网络算法流程如图3.1所示：


3.3基于遗传神经网络的股票预测模型

1，输入输出设计

遗传神经网络股票预测模型是BP预测模型的改进。为了比较测试，输入和输出与基于BP神经网络的股票预测模型一致。股价预测过程历史交易数据作为基础数据。与BP评估模型一样，遗传神经网络的预测模型也预测了第十一个交易日的收盘价，连续10个交易日的收盘价，即输入节点数量为10，输出数量节点为1。

2，BP网络设计

BP网络的设计主要考虑网络层数，每层神经元数，传递函数，网络学习算法，初始权重和阈值。

（1）网络层

BP神经网络结构与BP评估模型相同。

（2）隐藏层节点的数量

输入和输出节点数为10和1，隐层数量与BP预测模型中隐藏神经元数量一致。预测模型也是10-12-1网络模型。

（3）传递函数

输入层和隐含层由tansig函数传递，隐式和输出层与purelin函数一起传递。

（4）训练功能

遗传神经网络预测模型训练训练功能。

（5）初始体重

随机数由随机函数（-1,1）作为初始权重生成。

基于上述设计，构建了基于遗传神经网络的股票预测系统。具体过程如图4.3所示。


图3．2遗传BP神经网络预测模型的流程图

3.4总结

本文介绍了遗传算法优化BP神经网络的三种方法，并给出了遗传神经网络的构建步骤。最后提出了现有简单遗传神经网络的改进。基于遗传BP神经网络的股票预测模型是通过使用与BP神经网络预测模型相同的输入，输出和网络结构构建的，从而在第4章中比较和分析了两个模型的实验结果。




第四章模拟实验与结果分析

本章拟利用改进的遗传神经网络建立股票预测模型，选择上海和深圳300指数140个交易日的历史数据进行培训和测试网络，实现未来30天收盘价的预测。以MATLAB7.0为实验平台，进行实证分析。最后，将实验结果与简单的BP神经网络预测模型进行比较。结果表明，本文提出的股票预测模型具有一定的实际价值。

4.1实验数据集的选择和处理

从2014年1月2日至2014年7月28日，选择历史交易数据（从万德数据库）作为原始数据，如表4.1所示。计算第十一个交易日的收盘价，每十个交易日收盘价。


实验数据分为130组，前100组用作正常训练的培训样本。 随后30组用作测试样本，以测试训练效果。 训练样本如表4.2所示。



样本数据经归一化处理之后的结果如表4．3所示。


4.2实现股票预测

输入层有三个节点，输入层有10个节点，隐层中有12个节点，输出层只有一个节点。 网络结构如图4.1所示。


4.2.1BP神经网络实现股票预测

1，参数设置

（1）学习算法：Levenberg-Marquardt算法;

（2）传递函数：tansig，purelin：

（3）训练目标错误：1.0e-30：

（4）最高培训次数：2000次;

（5）适应度函数：平方误差的倒数。

2，训练过程

BP神经网络训练过程如图4.2所示，当训练次数达到26次时，误差目标值为1e-030并结束训练。


图4.2 BP神经网络训练过程

4.2.2遗传神经网络实现股票预测

1，参数设置

除学习率为自适应调整方法外，其余遗传神经网络模型参数设置与BP神经网络模型基本相同。

遗传算法的参数部分设置如下：

（1）初始种群数量：30;

（2）染色体长度：265;

（3）遗传代数：100;

（4）交叉概率：0.8。

2，训练过程

遗传BP神经网络训练18个步骤，收敛误差目标值1e-030和训练结束。 训练过程如图4.3所示。


遗传神经网络训练经过大约60代的搜索后染色体的平均适应度趋于稳定，误差平方和曲线和适应度曲线，如4.4和4.5所示。



从图可以看出。 4.4和图4.5遗传神经网络模型的预测速度相对较快。测试过程的错误接近于训练过程的错误。100组数据训练的过程中没有出现“过拟合”的现象，测试结果较好。

4.3实验结果与评价

4.3.1评估指标

实验采用三个指标的收敛性，准确性和稳定性作为评价标准。

1，网络训练过程的收敛根据步数Epochs来确定收敛速度。不同的网络实现相同的训练目标时，步数减少收敛速度，相反，步数多于慢收敛。

2，准确度根据不同网络测试模拟输出值和预期输出值的相对误差，确定训练网络测试后得到输出结果的准确性。其中，相对误差=（测试模拟输出值 - 预期输出）/预期输出* 100％。

3，稳定性根据网络测试仿真输出值和预期输出值的误差，计算不同网络测试输出均方误差（MSE），可以从宏观上进一步确定整个网络的稳定性。

4.3.2实验结果比较

1，收敛性

如图4.6所示，BP神经网络的收敛步骤为26，GA-BP网络的收敛步骤为18.当训练次数为26时，BP网络实现了网络训练误差目标1e-30而GA-BP网络只需要训练18个步骤来实现与BP评估模型相同的训练目标。


2、精确性

通过对BP网络模型和GA．BP网络模型分别进行测试，得到了测试仿真输出值

如表4．4所示。


从表4．4可以看出，相对于单纯的BP神经网络预测模型而言，遗传神经网络

的预测模型平均相对误差降低了30％。其预测结果与实际折线图如图4．7所示。


可以看出遗传神经网络的输出比BP网络输出更接近期望输出，可见，遗传算法与BP神经网络的结合不仅可以加快网络收敛速度，也提高了网络识别精度。



图4.8和图4.9显示，相比之下，由遗传神经网络测试输出产生的均方误差显着小于由BP网络测试输出产生的均方误差，并保持在一小段时间内，实质上，结果表明 BP神经网络的训练结果不稳定，单个测试输出的相对误差几乎达到5.65％，可能会降至局部最小值。

总之，遗传神经网络股票预测模型训练后，测试输出值和实际评估结果误差非常小，实验结果验证了遗传神经网络股票预测模型的准确性和合理性。

4.4总结

对基于BP神经网络和改进遗传神经网络算法的股票预测模型进行了模拟和验证，验证了遗传神经网络遗传预测模型的可靠性和准确性。





结论

股票诞生以来，人们不断探索股价预测方案。股市数据量非常大，可能导致股市波动很大因素，这些因素之间的关系也非常复杂。如何从庞大，复杂的非线性股票市场数据中提取有价值的数据对我们来说一直是一个难题。传统的统计方法和计量经济学方法难以建立基于这些大量，模糊和非线性股票市场数据的合适数学模型，不能对股票价格波动进行有效的分析和预测。

BP神经网络的基本原理是模拟人脑的思维，非线性模拟，自主学习等。使用具有非线性特征的BP神经网络可以模拟股票价格的运行。它总是在金融市场的数据分析中受到广大研究者的青睐。 BP神经网络可以根据训练数据调整内部节点之间的相互关系，达到学习数据变化的目的，从而能够预测未来一段时间内数据变化的趋势。在预测神经网络股价趋势的具体过程中，需要综合解决这三个问题。它们是输入量的问题，回溯窗口的选择，神经网络的算法和神经网络参数的确定。经济学家致力于BP神经网络在股票预测应用中的研究，在许多方面取得了显着成绩。然而，随着研究的深入，BP神经网络的缺陷逐渐暴露出来。主要问题是初始值是随机生成的，实际操作会导致收敛缓慢，一些数据不能收敛到全局最小点。

作为全局搜索算法，遗传算法在全局优化领域具有很强的适应性。因此，遗传算法可用于优化神经网络的初始权重和阈值。遗传算法的概念来自达尔文进化论和遗传学原理。它不依赖于问题本身，而是解决问题。遗传算法对问题优化过程的运行是完全随机的。在搜索过程中，我们只需要确定搜索方向的目标函数和相应的适应度函数，而不是寻求最优运算直到遗传代数或适应度为了达到目前的要求，解决方案是最好的解决方案到原来的问题。

遗传BP神经网络算法是弥补BP算法的缺点，提高算法效率，并利用遗传算法优化BP神经网络算法。遗传算法优化BP神经网络包括：优化连接权重和阈值，优化网络结构，并以三种方式优化学习规则。在本文中，改进的遗传神经网络用于通过遗传算法优化BP神经网络的权重和阈值。然后，通过试错法确定隐层节点的数量，构建BP神经网络的结构。最后，BP算法用于训练网络，学习率在训练过程中自动调整。

基于该算法，本文构建了一个股票预测模型，以Matlab7.0为实验平台进行了模拟实验。选择上海，深圳300个130组的历史数据。前100组数据用作培训样本，30组数据作为测试样本。实现未来30天收盘价的预测。同时，基于遗传BP神经网络和基于BP神经网络的BP神经网络的股票预测模型从三个方面进行了比较和分析：算法的收敛速度，遗传神经网络的稳定性和准确性预测结果。结果表明，基于遗传BP神经网络的提出的模型更好，预测结果更准确。

另外，一些地方的模式还需要进一步研究。如：特征数据的选择，只选择一个消息的收盘价，输入信息的特点太小，不能很好地回应股市的实际情况;部分网络参数设置，在随机给定参数之前导致结果的不确定性，如何确定参数以确保更好的网络性能和预测结果。




问题的提出

研究的前提（假设条件）

基本理论的阐述

数学模型的建立

推理


计算

理论成果的应用

验证及分析 
